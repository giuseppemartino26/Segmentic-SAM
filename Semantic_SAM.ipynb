{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuseppemartino26/Semantic-SAM/blob/main/Semantic_SAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pvRRbG0TxpV",
        "outputId": "c5bbea37-6177-4a5a-a6c9-a5824e206ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGBvi9IoNHL-"
      },
      "outputs": [],
      "source": [
        "\"\"\"Mean IoU (Intersection-over-Union) metric.\"\"\"\n",
        "\n",
        "from typing import Dict, Optional\n",
        "\n",
        "import datasets\n",
        "import numpy as np\n",
        "\n",
        "import evaluate\n",
        "\n",
        "\n",
        "_DESCRIPTION = \"\"\"\n",
        "IoU is the area of overlap between the predicted segmentation and the ground truth divided by the area of union\n",
        "between the predicted segmentation and the ground truth. For binary (two classes) or multi-class segmentation,\n",
        "the mean IoU of the image is calculated by taking the IoU of each class and averaging them.\n",
        "\"\"\"\n",
        "\n",
        "_KWARGS_DESCRIPTION = \"\"\"\n",
        "Args:\n",
        "    predictions (`List[ndarray]`):\n",
        "        List of predicted segmentation maps, each of shape (height, width). Each segmentation map can be of a different size.\n",
        "    references (`List[ndarray]`):\n",
        "        List of ground truth segmentation maps, each of shape (height, width). Each segmentation map can be of a different size.\n",
        "    num_labels (`int`):\n",
        "        Number of classes (categories).\n",
        "    ignore_index (`int`):\n",
        "        Index that will be ignored during evaluation.\n",
        "    nan_to_num (`int`, *optional*):\n",
        "        If specified, NaN values will be replaced by the number defined by the user.\n",
        "    label_map (`dict`, *optional*):\n",
        "        If specified, dictionary mapping old label indices to new label indices.\n",
        "    reduce_labels (`bool`, *optional*, defaults to `False`):\n",
        "        Whether or not to reduce all label values of segmentation maps by 1. Usually used for datasets where 0 is used for background,\n",
        "        and background itself is not included in all classes of a dataset (e.g. ADE20k). The background label will be replaced by 255.\n",
        "\n",
        "Returns:\n",
        "    `Dict[str, float | ndarray]` comprising various elements:\n",
        "    - *mean_iou* (`float`):\n",
        "        Mean Intersection-over-Union (IoU averaged over all categories).\n",
        "    - *mean_accuracy* (`float`):\n",
        "        Mean accuracy (averaged over all categories).\n",
        "    - *overall_accuracy* (`float`):\n",
        "        Overall accuracy on all images.\n",
        "    - *per_category_accuracy* (`ndarray` of shape `(num_labels,)`):\n",
        "        Per category accuracy.\n",
        "    - *per_category_iou* (`ndarray` of shape `(num_labels,)`):\n",
        "        Per category IoU.\n",
        "\n",
        "Examples:\n",
        "\n",
        "    >>> import numpy as np\n",
        "\n",
        "    >>> mean_iou = evaluate.load(\"mean_iou\")\n",
        "\n",
        "    >>> # suppose one has 3 different segmentation maps predicted\n",
        "    >>> predicted_1 = np.array([[1, 2], [3, 4], [5, 255]])\n",
        "    >>> actual_1 = np.array([[0, 3], [5, 4], [6, 255]])\n",
        "\n",
        "    >>> predicted_2 = np.array([[2, 7], [9, 2], [3, 6]])\n",
        "    >>> actual_2 = np.array([[1, 7], [9, 2], [3, 6]])\n",
        "\n",
        "    >>> predicted_3 = np.array([[2, 2, 3], [8, 2, 4], [3, 255, 2]])\n",
        "    >>> actual_3 = np.array([[1, 2, 2], [8, 2, 1], [3, 255, 1]])\n",
        "\n",
        "    >>> predicted = [predicted_1, predicted_2, predicted_3]\n",
        "    >>> ground_truth = [actual_1, actual_2, actual_3]\n",
        "\n",
        "    >>> results = mean_iou.compute(predictions=predicted, references=ground_truth, num_labels=10, ignore_index=255, reduce_labels=False)\n",
        "    >>> print(results) # doctest: +NORMALIZE_WHITESPACE\n",
        "    {'mean_iou': 0.47750000000000004, 'mean_accuracy': 0.5916666666666666, 'overall_accuracy': 0.5263157894736842, 'per_category_iou': array([0.   , 0.   , 0.375, 0.4  , 0.5  , 0.   , 0.5  , 1.   , 1.   , 1.   ]), 'per_category_accuracy': array([0.        , 0.        , 0.75      , 0.66666667, 1.        , 0.        , 0.5       , 1.        , 1.        , 1.        ])}\n",
        "\"\"\"\n",
        "\n",
        "_CITATION = \"\"\"\\\n",
        "@software{MMSegmentation_Contributors_OpenMMLab_Semantic_Segmentation_2020,\n",
        "author = {{MMSegmentation Contributors}},\n",
        "license = {Apache-2.0},\n",
        "month = {7},\n",
        "title = {{OpenMMLab Semantic Segmentation Toolbox and Benchmark}},\n",
        "url = {https://github.com/open-mmlab/mmsegmentation},\n",
        "year = {2020}\n",
        "}\"\"\"\n",
        "\n",
        "\n",
        "def intersect_and_union(\n",
        "    pred_label,\n",
        "    label,\n",
        "    num_labels,\n",
        "    ignore_index: bool,\n",
        "    label_map: Optional[Dict[int, int]] = None,\n",
        "    reduce_labels: bool = False,\n",
        "):\n",
        "    \"\"\"Calculate intersection and Union.\n",
        "\n",
        "    Args:\n",
        "        pred_label (`ndarray`):\n",
        "            Prediction segmentation map of shape (height, width).\n",
        "        label (`ndarray`):\n",
        "            Ground truth segmentation map of shape (height, width).\n",
        "        num_labels (`int`):\n",
        "            Number of categories.\n",
        "        ignore_index (`int`):\n",
        "            Index that will be ignored during evaluation.\n",
        "        label_map (`dict`, *optional*):\n",
        "            Mapping old labels to new labels. The parameter will work only when label is str.\n",
        "        reduce_labels (`bool`, *optional*, defaults to `False`):\n",
        "            Whether or not to reduce all label values of segmentation maps by 1. Usually used for datasets where 0 is used for background,\n",
        "            and background itself is not included in all classes of a dataset (e.g. ADE20k). The background label will be replaced by 255.\n",
        "\n",
        "     Returns:\n",
        "         area_intersect (`ndarray`):\n",
        "            The intersection of prediction and ground truth histogram on all classes.\n",
        "         area_union (`ndarray`):\n",
        "            The union of prediction and ground truth histogram on all classes.\n",
        "         area_pred_label (`ndarray`):\n",
        "            The prediction histogram on all classes.\n",
        "         area_label (`ndarray`):\n",
        "            The ground truth histogram on all classes.\n",
        "    \"\"\"\n",
        "    if label_map is not None:\n",
        "        for old_id, new_id in label_map.items():\n",
        "            label[label == old_id] = new_id\n",
        "\n",
        "    # turn into Numpy arrays\n",
        "    pred_label = np.array(pred_label)\n",
        "    label = np.array(label)\n",
        "\n",
        "    if reduce_labels:\n",
        "        label[label == 0] = 255\n",
        "        #label = label - 1\n",
        "        label[label == 254] = 255\n",
        "\n",
        "    mask = label != ignore_index\n",
        "    mask = np.not_equal(label, ignore_index)\n",
        "    pred_label = pred_label[mask]\n",
        "    label = np.array(label)[mask]\n",
        "\n",
        "    intersect = pred_label[pred_label == label]\n",
        "\n",
        "    area_intersect = np.histogram(intersect, bins=num_labels, range=(0, num_labels - 1))[0]\n",
        "    area_pred_label = np.histogram(pred_label, bins=num_labels, range=(0, num_labels - 1))[0]\n",
        "    area_label = np.histogram(label, bins=num_labels, range=(0, num_labels - 1))[0]\n",
        "\n",
        "    area_union = area_pred_label + area_label - area_intersect\n",
        "\n",
        "    return area_intersect, area_union, area_pred_label, area_label\n",
        "\n",
        "\n",
        "def total_intersect_and_union(\n",
        "    results,\n",
        "    gt_seg_maps,\n",
        "    num_labels,\n",
        "    ignore_index: bool,\n",
        "    label_map: Optional[Dict[int, int]] = None,\n",
        "    reduce_labels: bool = False,\n",
        "):\n",
        "    \"\"\"Calculate Total Intersection and Union, by calculating `intersect_and_union` for each (predicted, ground truth) pair.\n",
        "\n",
        "    Args:\n",
        "        results (`ndarray`):\n",
        "            List of prediction segmentation maps, each of shape (height, width).\n",
        "        gt_seg_maps (`ndarray`):\n",
        "            List of ground truth segmentation maps, each of shape (height, width).\n",
        "        num_labels (`int`):\n",
        "            Number of categories.\n",
        "        ignore_index (`int`):\n",
        "            Index that will be ignored during evaluation.\n",
        "        label_map (`dict`, *optional*):\n",
        "            Mapping old labels to new labels. The parameter will work only when label is str.\n",
        "        reduce_labels (`bool`, *optional*, defaults to `False`):\n",
        "            Whether or not to reduce all label values of segmentation maps by 1. Usually used for datasets where 0 is used for background,\n",
        "            and background itself is not included in all classes of a dataset (e.g. ADE20k). The background label will be replaced by 255.\n",
        "\n",
        "     Returns:\n",
        "         total_area_intersect (`ndarray`):\n",
        "            The intersection of prediction and ground truth histogram on all classes.\n",
        "         total_area_union (`ndarray`):\n",
        "            The union of prediction and ground truth histogram on all classes.\n",
        "         total_area_pred_label (`ndarray`):\n",
        "            The prediction histogram on all classes.\n",
        "         total_area_label (`ndarray`):\n",
        "            The ground truth histogram on all classes.\n",
        "    \"\"\"\n",
        "    total_area_intersect = np.zeros((num_labels,), dtype=np.float64)\n",
        "    total_area_union = np.zeros((num_labels,), dtype=np.float64)\n",
        "    total_area_pred_label = np.zeros((num_labels,), dtype=np.float64)\n",
        "    total_area_label = np.zeros((num_labels,), dtype=np.float64)\n",
        "    for result, gt_seg_map in zip(results, gt_seg_maps):\n",
        "        area_intersect, area_union, area_pred_label, area_label = intersect_and_union(\n",
        "            result, gt_seg_map, num_labels, ignore_index, label_map, reduce_labels\n",
        "        )\n",
        "        total_area_intersect += area_intersect\n",
        "        total_area_union += area_union\n",
        "        total_area_pred_label += area_pred_label\n",
        "        total_area_label += area_label\n",
        "    return total_area_intersect, total_area_union, total_area_pred_label, total_area_label\n",
        "\n",
        "\n",
        "def mean_iou(\n",
        "    results,\n",
        "    gt_seg_maps,\n",
        "    num_labels,\n",
        "    ignore_index: bool,\n",
        "    nan_to_num: Optional[int] = None,\n",
        "    label_map: Optional[Dict[int, int]] = None,\n",
        "    reduce_labels: bool = False,\n",
        "):\n",
        "    \"\"\"Calculate Mean Intersection and Union (mIoU).\n",
        "\n",
        "    Args:\n",
        "        results (`ndarray`):\n",
        "            List of prediction segmentation maps, each of shape (height, width).\n",
        "        gt_seg_maps (`ndarray`):\n",
        "            List of ground truth segmentation maps, each of shape (height, width).\n",
        "        num_labels (`int`):\n",
        "            Number of categories.\n",
        "        ignore_index (`int`):\n",
        "            Index that will be ignored during evaluation.\n",
        "        nan_to_num (`int`, *optional*):\n",
        "            If specified, NaN values will be replaced by the number defined by the user.\n",
        "        label_map (`dict`, *optional*):\n",
        "            Mapping old labels to new labels. The parameter will work only when label is str.\n",
        "        reduce_labels (`bool`, *optional*, defaults to `False`):\n",
        "            Whether or not to reduce all label values of segmentation maps by 1. Usually used for datasets where 0 is used for background,\n",
        "            and background itself is not included in all classes of a dataset (e.g. ADE20k). The background label will be replaced by 255.\n",
        "\n",
        "    Returns:\n",
        "        `Dict[str, float | ndarray]` comprising various elements:\n",
        "        - *mean_iou* (`float`):\n",
        "            Mean Intersection-over-Union (IoU averaged over all categories).\n",
        "        - *mean_accuracy* (`float`):\n",
        "            Mean accuracy (averaged over all categories).\n",
        "        - *overall_accuracy* (`float`):\n",
        "            Overall accuracy on all images.\n",
        "        - *per_category_accuracy* (`ndarray` of shape `(num_labels,)`):\n",
        "            Per category accuracy.\n",
        "        - *per_category_iou* (`ndarray` of shape `(num_labels,)`):\n",
        "            Per category IoU.\n",
        "    \"\"\"\n",
        "    total_area_intersect, total_area_union, total_area_pred_label, total_area_label = total_intersect_and_union(\n",
        "        results, gt_seg_maps, num_labels, ignore_index, label_map, reduce_labels\n",
        "    )\n",
        "\n",
        "    # compute metrics\n",
        "    metrics = dict()\n",
        "\n",
        "    all_acc = total_area_intersect.sum() / total_area_label.sum()\n",
        "    iou = total_area_intersect / total_area_union\n",
        "    acc = total_area_intersect / total_area_label\n",
        "\n",
        "    metrics[\"mean_iou\"] = np.nanmean(iou)\n",
        "    metrics[\"mean_accuracy\"] = np.nanmean(acc)\n",
        "    metrics[\"overall_accuracy\"] = all_acc\n",
        "    metrics[\"per_category_iou\"] = iou\n",
        "    metrics[\"per_category_accuracy\"] = acc\n",
        "\n",
        "    if nan_to_num is not None:\n",
        "        metrics = dict(\n",
        "            {metric: np.nan_to_num(metric_value, nan=nan_to_num) for metric, metric_value in metrics.items()}\n",
        "        )\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "@evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n",
        "class MeanIoU(evaluate.Metric):\n",
        "    def _info(self):\n",
        "        return evaluate.MetricInfo(\n",
        "            description=_DESCRIPTION,\n",
        "            citation=_CITATION,\n",
        "            inputs_description=_KWARGS_DESCRIPTION,\n",
        "            features=datasets.Features(\n",
        "                # 1st Seq - height dim, 2nd - width dim\n",
        "                {\n",
        "                    \"predictions\": datasets.Sequence(datasets.Sequence(datasets.Value(\"uint16\"))),\n",
        "                    \"references\": datasets.Sequence(datasets.Sequence(datasets.Value(\"uint16\"))),\n",
        "                }\n",
        "            ),\n",
        "            reference_urls=[\n",
        "                \"https://github.com/open-mmlab/mmsegmentation/blob/71c201b1813267d78764f306a297ca717827c4bf/mmseg/core/evaluation/metrics.py\"\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    def _compute(\n",
        "        self,\n",
        "        predictions,\n",
        "        references,\n",
        "        num_labels: int,\n",
        "        ignore_index: bool,\n",
        "        nan_to_num: Optional[int] = None,\n",
        "        label_map: Optional[Dict[int, int]] = None,\n",
        "        reduce_labels: bool = False,\n",
        "    ):\n",
        "        iou_result = mean_iou(\n",
        "            results=predictions,\n",
        "            gt_seg_maps=references,\n",
        "            num_labels=num_labels,\n",
        "            ignore_index=ignore_index,\n",
        "            nan_to_num=nan_to_num,\n",
        "            label_map=label_map,\n",
        "            reduce_labels=reduce_labels,\n",
        "        )\n",
        "        return iou_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROmUPj7fAF8N",
        "outputId": "c9cc89e9-f253-4db4-bdeb-4b9fa2137d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "PyTorch version: 2.0.1+cu118\n",
            "Torchvision version: 0.15.2+cu118\n",
            "CUDA is available: True\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-qcuzf545\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-qcuzf545\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment-anything\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36589 sha256=c3663a998af7d2f772606c9f4d502bfe007ea106e04daebba7cd4383aae0e538\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o_zxhhj8/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment-anything\n",
            "Installing collected packages: segment-anything\n",
            "Successfully installed segment-anything-1.0\n",
            "--2023-06-06 08:27:31--  https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 99846 (98K) [image/jpeg]\n",
            "Saving to: ‘images/dog.jpg’\n",
            "\n",
            "dog.jpg             100%[===================>]  97.51K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-06-06 08:27:31 (6.83 MB/s) - ‘images/dog.jpg’ saved [99846/99846]\n",
            "\n",
            "--2023-06-06 08:27:31--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.162.35, 108.157.162.108, 108.157.162.120, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.162.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
            "Saving to: ‘sam_vit_h_4b8939.pth’\n",
            "\n",
            "sam_vit_h_4b8939.pt 100%[===================>]   2.39G   131MB/s    in 18s     \n",
            "\n",
            "2023-06-06 08:27:49 (139 MB/s) - ‘sam_vit_h_4b8939.pth’ saved [2564550879/2564550879]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from google.colab import drive\n",
        "import csv\n",
        "import copy\n",
        "import shutil\n",
        "\n",
        "from datasets import load_metric\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#--------CREO CORRISPONDENZA TRA CLASSI PASCAL & ADE20K---------#\n",
        "class_PASCAL = [\n",
        "    'aeroplane',\n",
        "    'bicycle',\n",
        "    'bird',\n",
        "    'boat',\n",
        "    'bottle',\n",
        "    'bus',\n",
        "    'car',\n",
        "    'cat',\n",
        "    'chair',\n",
        "    'cow',\n",
        "    'diningtable',\n",
        "    'dog',\n",
        "    'horse',\n",
        "    'motorbike',\n",
        "    'person',\n",
        "    'pottedplant',\n",
        "    'sheep',\n",
        "    'sofa',\n",
        "    'train',\n",
        "    'tvmonitor'\n",
        "]\n",
        "\n",
        "class_ade20k_convertion=[91,128,0,77,99,81,21,0,20,0,0,0,0,117,13,0,0,24,0,0]\n",
        "\n",
        "\n",
        "using_colab = True\n",
        "\n",
        "if using_colab:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"Torchvision version:\", torchvision.__version__)\n",
        "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "    \n",
        "    !mkdir images\n",
        "    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n",
        "        \n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "\n",
        "\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "def show_anns(anns):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "\n",
        "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
        "    img[:,:,3] = 0\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
        "        img[m] = color_mask\n",
        "    ax.imshow(img)\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)\n",
        "\n",
        "def create_vect_dict(masks,total_classes,img_seg):\n",
        "    \"\"\"\n",
        "      Crea un dizionario di vettori per le maschere di segmentazione.\n",
        "\n",
        "      Args:\n",
        "          masks (list): Lista delle maschere di segmentazione.\n",
        "          total_classes (list): Lista delle classi totali.\n",
        "          img_seg (numpy.ndarray): Array dell'immagine di segmentazione.\n",
        "\n",
        "      Returns:\n",
        "          list: Lista di dizionari rappresentanti i vettori per ogni maschera.\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "    vect_dict = []\n",
        "    for mask in masks:\n",
        "        dict_class = dict.fromkeys(total_classes, 0)\n",
        "        for raw in range(0, len(mask['segmentation'])):\n",
        "            for col in range(0, len(mask['segmentation'][raw])):\n",
        "                if mask['segmentation'][raw][col]:\n",
        "                    dict_class[img_seg[raw][col]] += 1\n",
        "        vect_dict.append(dict_class)\n",
        "    return vect_dict\n",
        "\n",
        "\n",
        "def merge(masks,max_classes,img_seg):\n",
        "  i = 0\n",
        "  for mask in masks:\n",
        "      for raw in range(0, len(mask['segmentation'])):\n",
        "          for col in range(0, len(mask['segmentation'][raw])):\n",
        "              if mask['segmentation'][raw][col]:\n",
        "                  img_seg[raw][col] = max_classes[i]\n",
        "      i += 1\n",
        "  return img_seg\n",
        "\n",
        "def _get_voc_pallete(num_cls):\n",
        "    n = num_cls\n",
        "    pallete = [0]*(n*3)\n",
        "    for j in range(0,n):\n",
        "            lab = j\n",
        "            pallete[j*3+0] = 0\n",
        "            pallete[j*3+1] = 0\n",
        "            pallete[j*3+2] = 0\n",
        "            i = 0\n",
        "            while (lab > 0):\n",
        "                    pallete[j*3+0] |= (((lab >> 0) & 1) << (7-i))\n",
        "                    pallete[j*3+1] |= (((lab >> 1) & 1) << (7-i))\n",
        "                    pallete[j*3+2] |= (((lab >> 2) & 1) << (7-i))\n",
        "                    i = i + 1\n",
        "                    lab >>= 3\n",
        "    return pallete\n",
        "\n",
        "vocpallete = _get_voc_pallete(256)\n",
        "\n",
        "adepallete = [0,0,0,120,120,120,180,120,120,6,230,230,80,50,50,4,200,3,120,120,80,140,140,140,204,5,255,230,230,230,4,250,7,224,5,255,235,255,7,150,5,61,120,120,70,8,255,51,255,6,82,143,255,140,204,255,4,255,51,7,204,70,3,0,102,200,61,230,250,255,6,51,11,102,255,255,7,71,255,9,224,9,7,230,220,220,220,255,9,92,112,9,255,8,255,214,7,255,224,255,184,6,10,255,71,255,41,10,7,255,255,224,255,8,102,8,255,255,61,6,255,194,7,255,122,8,0,255,20,255,8,41,255,5,153,6,51,255,235,12,255,160,150,20,0,163,255,140,140,140,250,10,15,20,255,0,31,255,0,255,31,0,255,224,0,153,255,0,0,0,255,255,71,0,0,235,255,0,173,255,31,0,255,11,200,200,255,82,0,0,255,245,0,61,255,0,255,112,0,255,133,255,0,0,255,163,0,255,102,0,194,255,0,0,143,255,51,255,0,0,82,255,0,255,41,0,255,173,10,0,255,173,255,0,0,255,153,255,92,0,255,0,255,255,0,245,255,0,102,255,173,0,255,0,20,255,184,184,0,31,255,0,255,61,0,71,255,255,0,204,0,255,194,0,255,82,0,10,255,0,112,255,51,0,255,0,194,255,0,122,255,0,255,163,255,153,0,0,255,10,255,112,0,143,255,0,82,0,255,163,255,0,255,235,0,8,184,170,133,0,255,0,255,92,184,0,255,255,0,31,0,184,255,0,214,255,255,0,112,92,255,0,0,224,255,112,224,255,70,184,160,163,0,255,153,0,255,71,255,0,255,0,163,255,204,0,255,0,143,0,255,235,133,255,0,255,0,235,245,0,255,255,0,122,255,245,0,10,190,212,214,255,0,0,204,255,20,0,255,255,255,0,0,153,255,0,41,255,0,255,204,41,0,255,41,255,0,173,0,255,0,245,255,71,0,255,122,0,255,0,255,184,0,92,255,184,255,0,0,133,255,255,214,0,25,194,194,102,255,0,92,0,255]\n",
        "\n",
        "citypallete = [\n",
        "128,64,128,244,35,232,70,70,70,102,102,156,190,153,153,153,153,153,250,170,30,220,220,0,107,142,35,152,251,152,70,130,180,220,20,60,255,0,0,0,0,142,0,0,70,0,60,100,0,80,100,0,0,230,119,11,32,128,192,0,0,64,128,128,64,128,0,192,128,128,192,128,64,64,0,192,64,0,64,192,0,192,192,0,64,64,128,192,64,128,64,192,128,192,192,128,0,0,64,128,0,64,0,128,64,128,128,64,0,0,192,128,0,192,0,128,192,128,128,192,64,0,64,192,0,64,64,128,64,192,128,64,64,0,192,192,0,192,64,128,192,192,128,192,0,64,64,128,64,64,0,192,64,128,192,64,0,64,192,128,64,192,0,192,192,128,192,192,64,64,64,192,64,64,64,192,64,192,192,64,64,64,192,192,64,192,64,192,192,192,192,192,32,0,0,160,0,0,32,128,0,160,128,0,32,0,128,160,0,128,32,128,128,160,128,128,96,0,0,224,0,0,96,128,0,224,128,0,96,0,128,224,0,128,96,128,128,224,128,128,32,64,0,160,64,0,32,192,0,160,192,0,32,64,128,160,64,128,32,192,128,160,192,128,96,64,0,224,64,0,96,192,0,224,192,0,96,64,128,224,64,128,96,192,128,224,192,128,32,0,64,160,0,64,32,128,64,160,128,64,32,0,192,160,0,192,32,128,192,160,128,192,96,0,64,224,0,64,96,128,64,224,128,64,96,0,192,224,0,192,96,128,192,224,128,192,32,64,64,160,64,64,32,192,64,160,192,64,32,64,192,160,64,192,32,192,192,160,192,192,96,64,64,224,64,64,96,192,64,224,192,64,96,64,192,224,64,192,96,192,192,224,192,192,0,32,0,128,32,0,0,160,0,128,160,0,0,32,128,128,32,128,0,160,128,128,160,128,64,32,0,192,32,0,64,160,0,192,160,0,64,32,128,192,32,128,64,160,128,192,160,128,0,96,0,128,96,0,0,224,0,128,224,0,0,96,128,128,96,128,0,224,128,128,224,128,64,96,0,192,96,0,64,224,0,192,224,0,64,96,128,192,96,128,64,224,128,192,224,128,0,32,64,128,32,64,0,160,64,128,160,64,0,32,192,128,32,192,0,160,192,128,160,192,64,32,64,192,32,64,64,160,64,192,160,64,64,32,192,192,32,192,64,160,192,192,160,192,0,96,64,128,96,64,0,224,64,128,224,64,0,96,192,128,96,192,0,224,192,128,224,192,64,96,64,192,96,64,64,224,64,192,224,64,64,96,192,192,96,192,64,224,192,192,224,192,32,32,0,160,32,0,32,160,0,160,160,0,32,32,128,160,32,128,32,160,128,160,160,128,96,32,0,224,32,0,96,160,0,224,160,0,96,32,128,224,32,128,96,160,128,224,160,128,32,96,0,160,96,0,32,224,0,160,224,0,32,96,128,160,96,128,32,224,128,160,224,128,96,96,0,224,96,0,96,224,0,224,224,0,96,96,128,224,96,128,96,224,128,224,224,128,32,32,64,160,32,64,32,160,64,160,160,64,32,32,192,160,32,192,32,160,192,160,160,192,96,32,64,224,32,64,96,160,64,224,160,64,96,32,192,224,32,192,96,160,192,224,160,192,32,96,64,160,96,64,32,224,64,160,224,64,32,96,192,160,96,192,32,224,192,160,224,192,96,96,64,224,96,64,96,224,64,224,224,64,96,96,192,224,96,192,96,224,192,0,0,0]\n",
        "\n",
        "def get_mask_pallete(npimg, dataset='detail'):\n",
        "    \"\"\"Get image color pallete for visualizing masks\"\"\"\n",
        "    # recovery boundary\n",
        "    if dataset == 'pascal_voc':\n",
        "        npimg[npimg==21] = 255\n",
        "    # put colormap\n",
        "    out_img = Image.fromarray(npimg.squeeze().astype('uint8'))\n",
        "    if dataset == 'ade20k':\n",
        "        out_img.putpalette(adepallete)\n",
        "    elif dataset == 'citys':\n",
        "        out_img.putpalette(citypallete)\n",
        "    elif dataset in ('detail', 'pascal_voc', 'pascal_aug'):\n",
        "        out_img.putpalette(vocpallete)\n",
        "    return out_img\n",
        "\n",
        "\n",
        "def write_segm_img(path, image, labels, palette=\"detail\", alpha=0.5):\n",
        "    \"\"\"Write depth map to pfm and png file.\n",
        "\n",
        "    Args:\n",
        "        path (str): filepath without extension\n",
        "        image (array): input image\n",
        "        labels (array): labeling of the image\n",
        "    \"\"\"\n",
        "\n",
        "    mask = get_mask_pallete(labels, \"ade20k\")\n",
        "\n",
        "    img = Image.fromarray(np.uint8(255*image)).convert(\"RGBA\")\n",
        "    seg = mask.convert(\"RGBA\")\n",
        "\n",
        "    out = Image.blend(img, seg, alpha)\n",
        "\n",
        "    out.save(path + \".png\")\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def read_image(path):\n",
        "    \"\"\"Read image and output RGB image (0-1).\n",
        "\n",
        "    Args:\n",
        "        path (str): path to file\n",
        "\n",
        "    Returns:\n",
        "        array: RGB image (0-1)\n",
        "    \"\"\"\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    if img.ndim == 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n",
        "\n",
        "    return img\n",
        "\n",
        "def ade20k_to_pascalvoc(img_seg):\n",
        "    for i in range(0, len(img_seg)):\n",
        "        for j in range(0, len(img_seg[i])):\n",
        "            if img_seg[i][j] != 0:\n",
        "                if img_seg[i][j] in class_ade20k_convertion:\n",
        "                    img_seg[i][j] = class_ade20k_convertion.index(img_seg[i][j]) + 1\n",
        "                else:\n",
        "                    img_seg[i][j] = 0\n",
        "    return img_seg\n",
        "\n",
        "\n",
        "def dice_coefficient(class_matrix, matrix2):\n",
        "  intersection = 0\n",
        "  sum1 = 0\n",
        "  sum2 = 0\n",
        "  matrix2[matrix2 == 255] = False\n",
        "\n",
        "  for i in range(0, len(class_matrix)):\n",
        "        for j in range(0, len(class_matrix[i])):\n",
        "          if matrix2[i][j] == class_matrix[i][j] and matrix2[i][j] != 0:\n",
        "            intersection += 1\n",
        "\n",
        "          if class_matrix[i][j] != 0 and class_matrix[i][j] != 255:\n",
        "            sum1 += 1\n",
        "\n",
        "          if matrix2[i][j] != 0:\n",
        "            sum2 += 1\n",
        "          \n",
        "  dice = (2.0 * intersection) / (sum1 + sum2)\n",
        "  return dice\n",
        "\n",
        "\n",
        "def iou(class_matrix, matrix2):\n",
        "  intersection = 0\n",
        "  union = 0\n",
        "\n",
        "  for i in range(0, len(class_matrix)):\n",
        "        for j in range(0, len(class_matrix[i])):\n",
        "          if matrix2[i][j] == class_matrix[i][j] and matrix2[i][j] != 0:\n",
        "            intersection += 1\n",
        "\n",
        "          if matrix2[i][j] != 0 or (class_matrix[i][j] != 0 and class_matrix[i][j] != 255):\n",
        "            union += 1\n",
        "\n",
        "  iou_score = intersection / union\n",
        "  return iou_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm0kaylRB6SS",
        "outputId": "f590e8a9-b4be-4623-8eab-dcf2c4436710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/90 [00:00<?, ?it/s]<ipython-input-2-1a1af0960f2e>:246: RuntimeWarning: invalid value encountered in true_divide\n",
            "  iou = total_area_intersect / total_area_union\n",
            "<ipython-input-2-1a1af0960f2e>:247: RuntimeWarning: invalid value encountered in true_divide\n",
            "  acc = total_area_intersect / total_area_label\n",
            "100%|██████████| 90/90 [14:27<00:00,  9.63s/it]\n"
          ]
        }
      ],
      "source": [
        "  # Percorso della cartella contenente le immagini\n",
        "  import time\n",
        "  import json\n",
        "  from tqdm import tqdm\n",
        "  import evaluate\n",
        "\n",
        "  cartella_immagini = '/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/JPEGImages/'\n",
        "  # Ottieni la lista dei file nella cartella\n",
        "  elenco_file = os.listdir(cartella_immagini)\n",
        "  elenco_file.sort()\n",
        "  parti = np.array_split(elenco_file, 16)\n",
        "  # Loop attraverso tutti i file nella cartella\n",
        "  \n",
        "  dict_metrics= {} \n",
        "  #peppe:parti0 , 1, 2,3,4,5,6,7\n",
        "  #salvo: 8,9,10,11,12,13,14,15 \n",
        "  part = 14\n",
        "  for img_name in tqdm(parti[part]):\n",
        "      iou_sem_sam = {}\n",
        "      dice_sem_sam = {}\n",
        "      iou_sem = {}\n",
        "      dice_sem = {}\n",
        "      m_iou_sem = {}\n",
        "      m_iou_sem_sam = {}\n",
        "      img_name = img_name[:img_name.rindex(\".\")]\n",
        "    \n",
        "      matrix_path = f'/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/img_matrix/{img_name}.npy'  # semantic segmentation predictions\n",
        "      img_path = f'/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/JPEGImages/{img_name}'\n",
        "      ground_truth = f'/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/SegmentationClass/{img_name}'\n",
        "      dir_output = f\"/content/drive/MyDrive/results_only_match/output/{img_name}\"\n",
        "      # Verifica se la cartella esiste già\n",
        "      if os.path.exists(dir_output):\n",
        "          # Elimina la cartella se esiste già\n",
        "          shutil.rmtree(dir_output)\n",
        "\n",
        "\n",
        "      # Crea la cartella\n",
        "      os.mkdir(dir_output)\n",
        "\n",
        "      # Carica l'immagine di segmentazione true\n",
        "      image_path = ground_truth\n",
        "      segmentation_true = Image.open(f\"{image_path}.png\")\n",
        "\n",
        "      #image_rgb = segmentation_true.convert(\"RGB\")\n",
        "\n",
        "\n",
        "      # Salva l'immagine nella cartella specificata\n",
        "      #image_save_path = os.path.join(dir_output, \"segmentation_true.jpg\")\n",
        "      #image_rgb.save(image_save_path)\n",
        "\n",
        "      # Converti l'immagine in una matrice numpy\n",
        "      segmentation_array = np.array(segmentation_true)\n",
        "\n",
        "      #----1)-----------DICHIARO LA MATRICE CHE CONTIENE LE CLASSI DELLA SEGMENTATION TRUTH----------#\n",
        "      # Mappa i valori dei pixel agli indici di classe (0-20)\n",
        "      class_matrix = segmentation_array.astype(int)\n",
        "\n",
        "      #controllo se nell'immagine di segmentazione truth è vuota per ADE20K\n",
        "      class_sem = np.unique(class_matrix)[1:-1]\n",
        "      exist_class_sem = 0\n",
        "      for a in class_sem:\n",
        "        if class_ade20k_convertion[a - 1] == 0:\n",
        "          exist_class_sem += 1\n",
        "      if exist_class_sem > 0:\n",
        "        continue \n",
        "      #----2)-----------ESTRAGGO LE IMMAGINI DA SEGMENTARE CON SAM------#\n",
        "      inizio = time.time()\n",
        "      image = cv2.imread(f\"{img_path}.jpg\")\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      masks = mask_generator.generate(image) # all model mask\n",
        "\n",
        "      plt.figure(figsize=(20, 20))\n",
        "      plt.imshow(image)\n",
        "      show_anns(masks)\n",
        "      plt.axis('off')\n",
        "\n",
        "      plt.savefig(f'{dir_output}/SAM.png')\n",
        "      fine = time.time()\n",
        "      tempo_di_esecuzione_sam = fine - inizio\n",
        "\n",
        "      #----3)----------CARICHIAMO LA MATRICE DELLA PREDIZIONE SEMANTICA---------#\n",
        "\n",
        "      img_seg = np.load(matrix_path)\n",
        "      img_seg_dpt = copy.copy(img_seg)\n",
        "      \"\"\"\n",
        "      if os.path.isfile(f\"/content/drive/MyDrive/ProgettoSEAI/data/output_semseg/{img_name}.png\"):\n",
        "          # Sposta l'immagine nella cartella di destinazione\n",
        "          shutil.copy(f\"/content/drive/MyDrive/ProgettoSEAI/data/output_semseg/{img_name}.png\", f\"{dir_output}/semantic.png\")\n",
        "      else:\n",
        "         print(\"L'immagine di origine non esiste.\")\n",
        "      \"\"\"\n",
        "\n",
        "      #----4)---------MERGIAMO SEMANTICA E SAM----------------#\n",
        "      inizio = time.time()\n",
        "\n",
        "      total_classes = np.unique(img_seg_dpt)\n",
        "      dict_class = dict.fromkeys(total_classes, 0)\n",
        "\n",
        "      # Popoliamo un dict_class per ogni maschera dell'immagine. vect_dict è un array di dict_class\n",
        "\n",
        "      vect_dict = create_vect_dict(masks,total_classes,img_seg)\n",
        "\n",
        "      max_classes = []  # la classe di ogni maschera\n",
        "      for dict_mask in vect_dict:\n",
        "          max_classes.append(max(dict_mask, key=dict_mask.get))\n",
        "\n",
        "      img_seg = merge(masks,max_classes,img_seg)\n",
        "\n",
        "      img = read_image(f\"{img_path}.jpg\")\n",
        "      write_segm_img(f'{dir_output}/sem_plus_sam', img, img_seg, alpha=0.5)\n",
        "      \n",
        "      fine = time.time()\n",
        "      tempo_di_esecuzione_sam_sem = fine - inizio\n",
        "      #ADE20K to PASCAL_VOC\n",
        "      matrix_sem_plus_sam= ade20k_to_pascalvoc(img_seg)\n",
        "\n",
        "      matrix_only_sem = ade20k_to_pascalvoc(img_seg_dpt)\n",
        "\n",
        "      \n",
        "\n",
        "      iou_sem_sam[\"iou_sem_sam\"] = iou(class_matrix, matrix_sem_plus_sam)\n",
        "      dice_sem_sam[\"dice_sem_sam\"] = dice_coefficient(class_matrix, matrix_sem_plus_sam)\n",
        "      iou_sem[\"iou_sem\"] = iou(class_matrix, matrix_only_sem)\n",
        "      dice_sem[\"dice_sem\"] = dice_coefficient(class_matrix, matrix_only_sem)\n",
        "      m_iou_sem[\"m_iou_sem\"] = mean_iou(matrix_only_sem, class_matrix, num_labels=150, ignore_index=255)[\"mean_iou\"]\n",
        "      m_iou_sem_sam[\"m_iou_sem_sam\"] = mean_iou(matrix_sem_plus_sam, class_matrix, num_labels=150, ignore_index=255)[\"mean_iou\"]\n",
        "      dict_metrics[img_name] = [iou_sem_sam,dice_sem_sam,iou_sem,dice_sem,m_iou_sem,m_iou_sem_sam]\n",
        "      plt.close('all')\n",
        "\n",
        "    \n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "          \n",
        "  \n",
        "  with open(f\"/content/drive/MyDrive/results_only_match/metriche/dict_metrics{part}.json\", \"w\") as file:\n",
        "    #Scrivi il dizionario nel file in formato JSON\n",
        "    json.dump(dict_metrics, file)\n",
        " \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Solo per il report"
      ],
      "metadata": {
        "id": "QKUVAMMDKFPS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4985dd6f-3782-4e08-8384-c3554f903a14",
        "id": "STFYVNcCKJAs"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/90 [00:00<?, ?it/s]<ipython-input-2-1a1af0960f2e>:246: RuntimeWarning: invalid value encountered in true_divide\n",
            "  iou = total_area_intersect / total_area_union\n",
            "<ipython-input-2-1a1af0960f2e>:247: RuntimeWarning: invalid value encountered in true_divide\n",
            "  acc = total_area_intersect / total_area_label\n",
            "  0%|          | 0/90 [00:24<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "  # Percorso della cartella contenente le immagini\n",
        "  import time\n",
        "  import json\n",
        "  from tqdm import tqdm\n",
        "  import evaluate\n",
        "\n",
        "  cartella_immagini = '/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/JPEGImages/'\n",
        "  # Ottieni la lista dei file nella cartella\n",
        "  elenco_file = os.listdir(cartella_immagini)\n",
        "  elenco_file.sort()\n",
        "  parti = np.array_split(elenco_file, 16)\n",
        "  # Loop attraverso tutti i file nella cartella\n",
        "  \n",
        "  dict_metrics= {} \n",
        "  #peppe:parti0 , 1, 2,3,4,5,6,7\n",
        "  #salvo: 8,9,10,11,12,13,14,15 \n",
        "  part = 14\n",
        "  for img_name in tqdm(parti[part]):\n",
        "      iou_sem_sam = {}\n",
        "      dice_sem_sam = {}\n",
        "      iou_sem = {}\n",
        "      dice_sem = {}\n",
        "      m_iou_sem = {}\n",
        "      m_iou_sem_sam = {}\n",
        "      img_name = img_name[:img_name.rindex(\".\")]\n",
        "    \n",
        "      matrix_path = f'/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/img_matrix/2007_000129.npy'  # semantic segmentation predictions\n",
        "      img_path = f'/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/JPEGImages/2007_000129'\n",
        "      ground_truth = f'/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/SegmentationClass/2007_000129'\n",
        "      #dir_output = f\"/content/drive/MyDrive/results_only_match/output/2007_000129\"\n",
        "      # Verifica se la cartella esiste già\n",
        "      #if os.path.exists(dir_output):\n",
        "          # Elimina la cartella se esiste già\n",
        "          #shutil.rmtree(dir_output)\n",
        "\n",
        "\n",
        "      # Crea la cartella\n",
        "      #os.mkdir(dir_output)\n",
        "\n",
        "      # Carica l'immagine di segmentazione true\n",
        "      image_path = ground_truth\n",
        "      segmentation_true = Image.open(f\"{image_path}.png\")\n",
        "\n",
        "      #image_rgb = segmentation_true.convert(\"RGB\")\n",
        "\n",
        "\n",
        "      # Salva l'immagine nella cartella specificata\n",
        "      #image_save_path = os.path.join(dir_output, \"segmentation_true.jpg\")\n",
        "      #image_rgb.save(image_save_path)\n",
        "\n",
        "      # Converti l'immagine in una matrice numpy\n",
        "      segmentation_array = np.array(segmentation_true)\n",
        "\n",
        "      #----1)-----------DICHIARO LA MATRICE CHE CONTIENE LE CLASSI DELLA SEGMENTATION TRUTH----------#\n",
        "      # Mappa i valori dei pixel agli indici di classe (0-20)\n",
        "      class_matrix = segmentation_array.astype(int)\n",
        "\n",
        "      #controllo se nell'immagine di segmentazione truth è vuota per ADE20K\n",
        "      class_sem = np.unique(class_matrix)[1:-1]\n",
        "      exist_class_sem = 0\n",
        "      for a in class_sem:\n",
        "        if class_ade20k_convertion[a - 1] == 0:\n",
        "          exist_class_sem += 1\n",
        "      if exist_class_sem > 0:\n",
        "        continue \n",
        "      #----2)-----------ESTRAGGO LE IMMAGINI DA SEGMENTARE CON SAM------#\n",
        "      inizio = time.time()\n",
        "      image = cv2.imread(f\"{img_path}.jpg\")\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      masks = mask_generator.generate(image) # all model mask\n",
        "\n",
        "      plt.figure(figsize=(20, 20))\n",
        "      plt.imshow(image)\n",
        "      show_anns(masks)\n",
        "      plt.axis('off')\n",
        "\n",
        "      #plt.savefig(f'{dir_output}/SAM.png')\n",
        "      fine = time.time()\n",
        "      tempo_di_esecuzione_sam = fine - inizio\n",
        "\n",
        "      #----3)----------CARICHIAMO LA MATRICE DELLA PREDIZIONE SEMANTICA---------#\n",
        "\n",
        "      img_seg = np.load(matrix_path)\n",
        "      img_seg_dpt = copy.copy(img_seg)\n",
        "      \"\"\"\n",
        "      if os.path.isfile(f\"/content/drive/MyDrive/ProgettoSEAI/data/output_semseg/{img_name}.png\"):\n",
        "          # Sposta l'immagine nella cartella di destinazione\n",
        "          shutil.copy(f\"/content/drive/MyDrive/ProgettoSEAI/data/output_semseg/{img_name}.png\", f\"{dir_output}/semantic.png\")\n",
        "      else:\n",
        "         print(\"L'immagine di origine non esiste.\")\n",
        "      \"\"\"\n",
        "\n",
        "      #----4)---------MERGIAMO SEMANTICA E SAM----------------#\n",
        "      inizio = time.time()\n",
        "\n",
        "      total_classes = np.unique(img_seg_dpt)\n",
        "      dict_class = dict.fromkeys(total_classes, 0)\n",
        "\n",
        "      # Popoliamo un dict_class per ogni maschera dell'immagine. vect_dict è un array di dict_class\n",
        "\n",
        "      vect_dict = create_vect_dict(masks,total_classes,img_seg)\n",
        "\n",
        "      max_classes = []  # la classe di ogni maschera\n",
        "      for dict_mask in vect_dict:\n",
        "          max_classes.append(max(dict_mask, key=dict_mask.get))\n",
        "\n",
        "      img_seg = merge(masks,max_classes,img_seg)\n",
        "\n",
        "      img = read_image(f\"{img_path}.jpg\")\n",
        "      #write_segm_img(f'{dir_output}/sem_plus_sam', img, img_seg, alpha=0.5)\n",
        "      \n",
        "      fine = time.time()\n",
        "      tempo_di_esecuzione_sam_sem = fine - inizio\n",
        "      #ADE20K to PASCAL_VOC\n",
        "      matrix_sem_plus_sam= ade20k_to_pascalvoc(img_seg)\n",
        "\n",
        "      matrix_only_sem = ade20k_to_pascalvoc(img_seg_dpt)\n",
        "\n",
        "      \n",
        "\n",
        "      iou_sem_sam[\"iou_sem_sam\"] = iou(class_matrix, matrix_sem_plus_sam)\n",
        "      dice_sem_sam[\"dice_sem_sam\"] = dice_coefficient(class_matrix, matrix_sem_plus_sam)\n",
        "      iou_sem[\"iou_sem\"] = iou(class_matrix, matrix_only_sem)\n",
        "      dice_sem[\"dice_sem\"] = dice_coefficient(class_matrix, matrix_only_sem)\n",
        "      m_iou_sem[\"m_iou_sem\"] = mean_iou(matrix_only_sem, class_matrix, num_labels=150, ignore_index=255)[\"mean_iou\"]\n",
        "      m_iou_sem_sam[\"m_iou_sem_sam\"] = mean_iou(matrix_sem_plus_sam, class_matrix, num_labels=150, ignore_index=255)[\"mean_iou\"]\n",
        "      dict_metrics[img_name] = [iou_sem_sam,dice_sem_sam,iou_sem,dice_sem,m_iou_sem,m_iou_sem_sam]\n",
        "      plt.close('all')\n",
        "\n",
        "      break\n",
        "\n",
        "    \n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "          \n",
        "  \n",
        "  #with open(f\"/content/drive/MyDrive/results_only_match/metriche/dict_metrics{part}.json\", \"w\") as file:\n",
        "    #Scrivi il dizionario nel file in formato JSON\n",
        "    #json.dump(dict_metrics, file)\n",
        " \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tempo_di_esecuzione_sam_sem"
      ],
      "metadata": {
        "id": "OWxRdkHuQ_wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d7f2f3-99ab-427e-cf8c-d1e0ea95e198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.9930925369262695"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_sem = get_mask_pallete(matrix_only_sem, \"pascal_voc\")\n",
        "img_sem = mask_sem.convert(\"RGBA\")\n",
        "\n",
        "mask_sem_sam = get_mask_pallete(matrix_sem_plus_sam, \"pascal_voc\")\n",
        "img_sem_sam = mask_sem_sam.convert(\"RGBA\")"
      ],
      "metadata": {
        "id": "KViYgzRo9IiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(f\"/content/drive/MyDrive/ProgettoSEAI/output/2007_000129/sem_mask_sem_sam.npy\", img_sem)"
      ],
      "metadata": {
        "id": "BpskXeGCnFE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_sem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "QVBI9ip1nlTZ",
        "outputId": "d4da26c5-accb-4873-f2b2-5a8522b0fdfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=334x500 at 0x7F37D4426DD0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Crea una griglia di sottoplot 1x3\n",
        "fig, axes = plt.subplots(1, 3, figsize=(10, 8))\n",
        "\n",
        "# Visualizza le immagini nei sottoplot\n",
        "axes[0].imshow(segmentation_true)\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title(\"Ground Truth annotation\")\n",
        "\n",
        "axes[1].imshow(img_sem)\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title(\"Semantic segmentation (DPT)\")\n",
        "\n",
        "axes[2].imshow(img_sem_sam)\n",
        "axes[2].axis('off')\n",
        "axes[2].set_title(\"DPT + SAM\")\n",
        "\n",
        "# Regola automaticamente il layout dei sottoplot\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostra il plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "jICS9G5DEEst",
        "outputId": "1534efaf-c86f-4de1-bcf8-d826d56495b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(seg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nhBJh5A_X--",
        "outputId": "27bdcb4f-64c7-461f-b84a-bb8bd1d04710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PIL.Image.Image"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHXtW9NO9ISl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1j7Cgr7A6kg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t53yDZfN2HjJ",
        "outputId": "e2997e8e-63bd-4f6f-e7a7-b9b8eff2e14c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12.920941591262817\n",
            "8.711585521697998\n"
          ]
        }
      ],
      "source": [
        "print(tempo_di_esecuzione_sam_sem)\n",
        "print(tempo_di_esecuzione_sam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQs2BzhxYR-H",
        "outputId": "a37cb98d-1bed-461c-ccb2-c0cd46b0d519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DICE segmentazione finale: 0.8379192890483733\n",
            "IOU segmentazione finale: 0.721050853999807\n",
            "DICE segmentazione semantica: 0.8514332087064893\n",
            "IOU segmentazione semantica: 0.7413005627192207\n",
            "0.48306235252286905\n",
            "0.4747874713126677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-1a1af0960f2e>:246: RuntimeWarning: invalid value encountered in true_divide\n",
            "  iou = total_area_intersect / total_area_union\n",
            "<ipython-input-2-1a1af0960f2e>:247: RuntimeWarning: invalid value encountered in true_divide\n",
            "  acc = total_area_intersect / total_area_label\n"
          ]
        }
      ],
      "source": [
        "print(f\"DICE segmentazione finale: {dice_coefficient(class_matrix,img_seg)}\")\n",
        "print(f\"IOU segmentazione finale: {iou(class_matrix,img_seg)}\")\n",
        "print(f\"DICE segmentazione semantica: {dice_coefficient(class_matrix,img_seg_dpt)}\")\n",
        "print(f\"IOU segmentazione semantica: {iou(class_matrix,img_seg_dpt)}\")\n",
        "print(mean_iou(matrix_sem_plus_sam, class_matrix, num_labels=10, ignore_index=255, reduce_labels=True)[\"mean_iou\"])\n",
        "print(mean_iou(matrix_only_sem, class_matrix, num_labels=10, ignore_index=255, reduce_labels=True)[\"mean_iou\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSsz1U5rG6by"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y_wxQGVG6az",
        "outputId": "6394e984-667d-4889-a0fe-3cd55a4f707b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 7])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(matrix_sem_plus_sam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "309t33u9G6aH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMpNRvnENHO5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENLxXFSVOBjB"
      },
      "outputs": [],
      "source": [
        "metrica = MeanIoU()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA4v08zCI7N0",
        "outputId": "25135f77-0acd-46e2-fefa-5d035454854e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-1a1af0960f2e>:246: RuntimeWarning: invalid value encountered in true_divide\n",
            "  iou = total_area_intersect / total_area_union\n",
            "<ipython-input-112-1a1af0960f2e>:247: RuntimeWarning: invalid value encountered in true_divide\n",
            "  acc = total_area_intersect / total_area_label\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#mean_iou = evaluate.load(\"mean_iou\")\n",
        "predicted = np.array([[0, 0, 5], [0, 1, 2], [0, 0, 0]])\n",
        "ground_truth = np.array([[0, 0, 4], [0, 2, 2], [0, 0, 255]])\n",
        "results = mean_iou(predicted,ground_truth, num_labels=150, ignore_index=255, reduce_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX-z7QRYO19o",
        "outputId": "c357b817-9498-416c-c6bc-b3a05ca6765e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.125"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results['mean_iou']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkjXT1G_6FbO",
        "outputId": "5b71116d-30b7-4abd-897a-738398c72970"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iou(predicted, ground_truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp303Oi02ws6",
        "outputId": "779b4534-60a1-4b5b-e16a-1fd2623dc3ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output Array :  [ True  True False  True]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# input\n",
        "arr1 = [1, 0, False, 4]\n",
        "arr2 = [2, 5, 0, False]\n",
        "\n",
        "# output\n",
        "out_arr = np.logical_or(arr1, arr2)\n",
        "\n",
        "print (\"Output Array : \", out_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LtAQ1wpoLJo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}