{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuseppemartino26/Semantic-SAM/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROmUPj7fAF8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09adf5c7-f3be-402f-9018-aebd20e7c4f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "PyTorch version: 2.0.0+cu118\n",
            "Torchvision version: 0.15.1+cu118\n",
            "CUDA is available: True\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-e7jm87pq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-e7jm87pq\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "mkdir: cannot create directory ‘images’: File exists\n",
            "--2023-05-18 08:51:05--  https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 99846 (98K) [image/jpeg]\n",
            "Saving to: ‘images/dog.jpg.1’\n",
            "\n",
            "dog.jpg.1           100%[===================>]  97.51K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-05-18 08:51:05 (36.2 MB/s) - ‘images/dog.jpg.1’ saved [99846/99846]\n",
            "\n",
            "--2023-05-18 08:51:05--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 52.84.251.106, 52.84.251.15, 52.84.251.27, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|52.84.251.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
            "Saving to: ‘sam_vit_h_4b8939.pth.1’\n",
            "\n",
            "sam_vit_h_4b8939.pt 100%[===================>]   2.39G   175MB/s    in 18s     \n",
            "\n",
            "2023-05-18 08:51:24 (133 MB/s) - ‘sam_vit_h_4b8939.pth.1’ saved [2564550879/2564550879]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from google.colab import drive\n",
        "import csv\n",
        "import copy\n",
        "import shutil\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#--------CREO CORRISPONDENZA TRA CLASSI PASCAL & ADE20K---------#\n",
        "class_PASCAL = [\n",
        "    'aeroplane',\n",
        "    'bicycle',\n",
        "    'bird',\n",
        "    'boat',\n",
        "    'bottle',\n",
        "    'bus',\n",
        "    'car',\n",
        "    'cat',\n",
        "    'chair',\n",
        "    'cow',\n",
        "    'diningtable',\n",
        "    'dog',\n",
        "    'horse',\n",
        "    'motorbike',\n",
        "    'person',\n",
        "    'pottedplant',\n",
        "    'sheep',\n",
        "    'sofa',\n",
        "    'train',\n",
        "    'tvmonitor'\n",
        "]\n",
        "\n",
        "class_ade20k_convertion=[91,128,0,77,99,81,21,0,20,0,0,0,0,117,13,0,0,24,0,0]\n",
        "\n",
        "\n",
        "using_colab = True\n",
        "\n",
        "if using_colab:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"Torchvision version:\", torchvision.__version__)\n",
        "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "    \n",
        "    !mkdir images\n",
        "    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n",
        "        \n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "\n",
        "\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "def show_anns(anns):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "\n",
        "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
        "    img[:,:,3] = 0\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
        "        img[m] = color_mask\n",
        "    ax.imshow(img)\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)\n",
        "\n",
        "def create_vect_dict(masks,total_classes,img_seg):\n",
        "    \"\"\"\n",
        "      Crea un dizionario di vettori per le maschere di segmentazione.\n",
        "\n",
        "      Args:\n",
        "          masks (list): Lista delle maschere di segmentazione.\n",
        "          total_classes (list): Lista delle classi totali.\n",
        "          img_seg (numpy.ndarray): Array dell'immagine di segmentazione.\n",
        "\n",
        "      Returns:\n",
        "          list: Lista di dizionari rappresentanti i vettori per ogni maschera.\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "    vect_dict = []\n",
        "    for mask in masks:\n",
        "        dict_class = dict.fromkeys(total_classes, 0)\n",
        "        for raw in range(0, len(mask['segmentation'])):\n",
        "            for col in range(0, len(mask['segmentation'][raw])):\n",
        "                if mask['segmentation'][raw][col]:\n",
        "                    dict_class[img_seg[raw][col]] += 1\n",
        "        vect_dict.append(dict_class)\n",
        "    return vect_dict\n",
        "\n",
        "\n",
        "def merge(masks,max_classes,img_seg):\n",
        "  i = 0\n",
        "  for mask in masks:\n",
        "      for raw in range(0, len(mask['segmentation'])):\n",
        "          for col in range(0, len(mask['segmentation'][raw])):\n",
        "              if mask['segmentation'][raw][col]:\n",
        "                  img_seg[raw][col] = max_classes[i]\n",
        "      i += 1\n",
        "  return img_seg\n",
        "\n",
        "def _get_voc_pallete(num_cls):\n",
        "    n = num_cls\n",
        "    pallete = [0]*(n*3)\n",
        "    for j in range(0,n):\n",
        "            lab = j\n",
        "            pallete[j*3+0] = 0\n",
        "            pallete[j*3+1] = 0\n",
        "            pallete[j*3+2] = 0\n",
        "            i = 0\n",
        "            while (lab > 0):\n",
        "                    pallete[j*3+0] |= (((lab >> 0) & 1) << (7-i))\n",
        "                    pallete[j*3+1] |= (((lab >> 1) & 1) << (7-i))\n",
        "                    pallete[j*3+2] |= (((lab >> 2) & 1) << (7-i))\n",
        "                    i = i + 1\n",
        "                    lab >>= 3\n",
        "    return pallete\n",
        "\n",
        "vocpallete = _get_voc_pallete(256)\n",
        "\n",
        "adepallete = [0,0,0,120,120,120,180,120,120,6,230,230,80,50,50,4,200,3,120,120,80,140,140,140,204,5,255,230,230,230,4,250,7,224,5,255,235,255,7,150,5,61,120,120,70,8,255,51,255,6,82,143,255,140,204,255,4,255,51,7,204,70,3,0,102,200,61,230,250,255,6,51,11,102,255,255,7,71,255,9,224,9,7,230,220,220,220,255,9,92,112,9,255,8,255,214,7,255,224,255,184,6,10,255,71,255,41,10,7,255,255,224,255,8,102,8,255,255,61,6,255,194,7,255,122,8,0,255,20,255,8,41,255,5,153,6,51,255,235,12,255,160,150,20,0,163,255,140,140,140,250,10,15,20,255,0,31,255,0,255,31,0,255,224,0,153,255,0,0,0,255,255,71,0,0,235,255,0,173,255,31,0,255,11,200,200,255,82,0,0,255,245,0,61,255,0,255,112,0,255,133,255,0,0,255,163,0,255,102,0,194,255,0,0,143,255,51,255,0,0,82,255,0,255,41,0,255,173,10,0,255,173,255,0,0,255,153,255,92,0,255,0,255,255,0,245,255,0,102,255,173,0,255,0,20,255,184,184,0,31,255,0,255,61,0,71,255,255,0,204,0,255,194,0,255,82,0,10,255,0,112,255,51,0,255,0,194,255,0,122,255,0,255,163,255,153,0,0,255,10,255,112,0,143,255,0,82,0,255,163,255,0,255,235,0,8,184,170,133,0,255,0,255,92,184,0,255,255,0,31,0,184,255,0,214,255,255,0,112,92,255,0,0,224,255,112,224,255,70,184,160,163,0,255,153,0,255,71,255,0,255,0,163,255,204,0,255,0,143,0,255,235,133,255,0,255,0,235,245,0,255,255,0,122,255,245,0,10,190,212,214,255,0,0,204,255,20,0,255,255,255,0,0,153,255,0,41,255,0,255,204,41,0,255,41,255,0,173,0,255,0,245,255,71,0,255,122,0,255,0,255,184,0,92,255,184,255,0,0,133,255,255,214,0,25,194,194,102,255,0,92,0,255]\n",
        "\n",
        "citypallete = [\n",
        "128,64,128,244,35,232,70,70,70,102,102,156,190,153,153,153,153,153,250,170,30,220,220,0,107,142,35,152,251,152,70,130,180,220,20,60,255,0,0,0,0,142,0,0,70,0,60,100,0,80,100,0,0,230,119,11,32,128,192,0,0,64,128,128,64,128,0,192,128,128,192,128,64,64,0,192,64,0,64,192,0,192,192,0,64,64,128,192,64,128,64,192,128,192,192,128,0,0,64,128,0,64,0,128,64,128,128,64,0,0,192,128,0,192,0,128,192,128,128,192,64,0,64,192,0,64,64,128,64,192,128,64,64,0,192,192,0,192,64,128,192,192,128,192,0,64,64,128,64,64,0,192,64,128,192,64,0,64,192,128,64,192,0,192,192,128,192,192,64,64,64,192,64,64,64,192,64,192,192,64,64,64,192,192,64,192,64,192,192,192,192,192,32,0,0,160,0,0,32,128,0,160,128,0,32,0,128,160,0,128,32,128,128,160,128,128,96,0,0,224,0,0,96,128,0,224,128,0,96,0,128,224,0,128,96,128,128,224,128,128,32,64,0,160,64,0,32,192,0,160,192,0,32,64,128,160,64,128,32,192,128,160,192,128,96,64,0,224,64,0,96,192,0,224,192,0,96,64,128,224,64,128,96,192,128,224,192,128,32,0,64,160,0,64,32,128,64,160,128,64,32,0,192,160,0,192,32,128,192,160,128,192,96,0,64,224,0,64,96,128,64,224,128,64,96,0,192,224,0,192,96,128,192,224,128,192,32,64,64,160,64,64,32,192,64,160,192,64,32,64,192,160,64,192,32,192,192,160,192,192,96,64,64,224,64,64,96,192,64,224,192,64,96,64,192,224,64,192,96,192,192,224,192,192,0,32,0,128,32,0,0,160,0,128,160,0,0,32,128,128,32,128,0,160,128,128,160,128,64,32,0,192,32,0,64,160,0,192,160,0,64,32,128,192,32,128,64,160,128,192,160,128,0,96,0,128,96,0,0,224,0,128,224,0,0,96,128,128,96,128,0,224,128,128,224,128,64,96,0,192,96,0,64,224,0,192,224,0,64,96,128,192,96,128,64,224,128,192,224,128,0,32,64,128,32,64,0,160,64,128,160,64,0,32,192,128,32,192,0,160,192,128,160,192,64,32,64,192,32,64,64,160,64,192,160,64,64,32,192,192,32,192,64,160,192,192,160,192,0,96,64,128,96,64,0,224,64,128,224,64,0,96,192,128,96,192,0,224,192,128,224,192,64,96,64,192,96,64,64,224,64,192,224,64,64,96,192,192,96,192,64,224,192,192,224,192,32,32,0,160,32,0,32,160,0,160,160,0,32,32,128,160,32,128,32,160,128,160,160,128,96,32,0,224,32,0,96,160,0,224,160,0,96,32,128,224,32,128,96,160,128,224,160,128,32,96,0,160,96,0,32,224,0,160,224,0,32,96,128,160,96,128,32,224,128,160,224,128,96,96,0,224,96,0,96,224,0,224,224,0,96,96,128,224,96,128,96,224,128,224,224,128,32,32,64,160,32,64,32,160,64,160,160,64,32,32,192,160,32,192,32,160,192,160,160,192,96,32,64,224,32,64,96,160,64,224,160,64,96,32,192,224,32,192,96,160,192,224,160,192,32,96,64,160,96,64,32,224,64,160,224,64,32,96,192,160,96,192,32,224,192,160,224,192,96,96,64,224,96,64,96,224,64,224,224,64,96,96,192,224,96,192,96,224,192,0,0,0]\n",
        "\n",
        "def get_mask_pallete(npimg, dataset='detail'):\n",
        "    \"\"\"Get image color pallete for visualizing masks\"\"\"\n",
        "    # recovery boundary\n",
        "    if dataset == 'pascal_voc':\n",
        "        npimg[npimg==21] = 255\n",
        "    # put colormap\n",
        "    out_img = Image.fromarray(npimg.squeeze().astype('uint8'))\n",
        "    if dataset == 'ade20k':\n",
        "        out_img.putpalette(adepallete)\n",
        "    elif dataset == 'citys':\n",
        "        out_img.putpalette(citypallete)\n",
        "    elif dataset in ('detail', 'pascal_voc', 'pascal_aug'):\n",
        "        out_img.putpalette(vocpallete)\n",
        "    return out_img\n",
        "\n",
        "\n",
        "def write_segm_img(path, image, labels, palette=\"detail\", alpha=0.5):\n",
        "    \"\"\"Write depth map to pfm and png file.\n",
        "\n",
        "    Args:\n",
        "        path (str): filepath without extension\n",
        "        image (array): input image\n",
        "        labels (array): labeling of the image\n",
        "    \"\"\"\n",
        "\n",
        "    mask = get_mask_pallete(labels, \"ade20k\")\n",
        "\n",
        "    img = Image.fromarray(np.uint8(255*image)).convert(\"RGBA\")\n",
        "    seg = mask.convert(\"RGBA\")\n",
        "\n",
        "    out = Image.blend(img, seg, alpha)\n",
        "\n",
        "    out.save(path + \".png\")\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def read_image(path):\n",
        "    \"\"\"Read image and output RGB image (0-1).\n",
        "\n",
        "    Args:\n",
        "        path (str): path to file\n",
        "\n",
        "    Returns:\n",
        "        array: RGB image (0-1)\n",
        "    \"\"\"\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    if img.ndim == 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n",
        "\n",
        "    return img\n",
        "\n",
        "def ade20k_to_pascalvoc(img_seg):\n",
        "    for i in range(0, len(img_seg)):\n",
        "        for j in range(0, len(img_seg[i])):\n",
        "            if img_seg[i][j] != 0:\n",
        "                if img_seg[i][j] in class_ade20k_convertion:\n",
        "                    img_seg[i][j] = class_ade20k_convertion.index(img_seg[i][j]) + 1\n",
        "                else:\n",
        "                    img_seg[i][j] = 0\n",
        "    return img_seg\n",
        "\n",
        "\n",
        "def dice_coefficient(class_matrix, matrix2):\n",
        "    intersection = 0\n",
        "    insieme1 = 0\n",
        "    insieme2 = 0\n",
        "    \n",
        "    for i in range(0, len(class_matrix)):\n",
        "        for j in range(0, len(class_matrix[i])):\n",
        "            if matrix2[i][j] != 0:\n",
        "              insieme1 += 1\n",
        "            \n",
        "            if class_matrix[i][j] != 0 and class_matrix[i][j] != 255:\n",
        "                if class_ade20k_convertion[class_matrix[i][j] - 1] == 0:\n",
        "                    continue\n",
        "                else:\n",
        "                  insieme2 += 1\n",
        "                  if matrix2[i][j] == class_matrix[i][j]:\n",
        "                    intersection += 1\n",
        "\n",
        "            \n",
        "\n",
        "              \n",
        "\n",
        "    tot_insiemi= insieme1 +insieme2        \n",
        "   \n",
        "    if tot_insiemi == 0:\n",
        "        return -1\n",
        "    dice = (2.0 * intersection) / (tot_insiemi)\n",
        "    # print(intersection)\n",
        "    return dice\n",
        "\n",
        "\n",
        "def iou(class_matrix, matrix2):\n",
        "    intersection = 0\n",
        "    union = 0\n",
        "    \n",
        "    for i in range(0, len(class_matrix)):\n",
        "        for j in range(0, len(class_matrix[i])):\n",
        "          if matrix2[i][j] != 0:\n",
        "            union += 1\n",
        "            if class_matrix[i][j] == matrix2[i][j]:\n",
        "              intersection += 1\n",
        "              continue\n",
        "\n",
        "          if class_matrix[i][j] != 0 and class_matrix[i][j] != 255:\n",
        "                if class_ade20k_convertion[class_matrix[i][j] - 1] == 0:\n",
        "                    continue\n",
        "                else:\n",
        "                  union += 1\n",
        "                  \n",
        "            \n",
        "   \n",
        "    if union == 0:\n",
        "        return -1\n",
        "    iou = intersection / union\n",
        "    return iou\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Percorso della cartella contenente le immagini\n",
        "  import time\n",
        "  import json\n",
        "  from tqdm import tqdm\n",
        "\n",
        "  cartella_immagini = '/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/JPEGImages/'\n",
        "  # Ottieni la lista dei file nella cartella\n",
        "  elenco_file = os.listdir(cartella_immagini)\n",
        "  elenco_file.sort()\n",
        "  parti = np.array_split(elenco_file, 16)\n",
        "  # Loop attraverso tutti i file nella cartella\n",
        "  \n",
        "  dict_metrics= {} \n",
        "  #peppe:parti0 , 1, 2,3,4,5,6,7\n",
        "  #salvo: 8,9,10,11,12,13,14,15 \n",
        "  part = 5\n",
        "  for img_name in tqdm(parti[part]):\n",
        "      iou_sem_sam = {}\n",
        "      dice_sem_sam = {}\n",
        "      iou_sem = {}\n",
        "      dice_sem = {}\n",
        "      img_name = img_name[:img_name.rindex(\".\")]\n",
        "    \n",
        "      matrix_path = f'/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/img_matrix/{img_name}.npy'  # semantic segmentation predictions\n",
        "      img_path = f'/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/JPEGImages/{img_name}'\n",
        "      ground_truth = f'/content/drive/MyDrive/ProgettoSEAI/data/pascal_voc/SegmentationClass/{img_name}'\n",
        "      dir_output = f\"/content/drive/MyDrive/ProgettoSEAI/output/{img_name}\"\n",
        "      # Verifica se la cartella esiste già\n",
        "      if os.path.exists(dir_output):\n",
        "          # Elimina la cartella se esiste già\n",
        "          shutil.rmtree(dir_output)\n",
        "\n",
        "\n",
        "      # Crea la cartella\n",
        "      os.mkdir(dir_output)\n",
        "\n",
        "      # Carica l'immagine di segmentazione true\n",
        "      image_path = ground_truth\n",
        "      segmentation_true = Image.open(f\"{image_path}.png\")\n",
        "\n",
        "      image_rgb = segmentation_true.convert(\"RGB\")\n",
        "\n",
        "\n",
        "      # Salva l'immagine nella cartella specificata\n",
        "      image_save_path = os.path.join(dir_output, \"segmentation_true.jpg\")\n",
        "      image_rgb.save(image_save_path)\n",
        "\n",
        "      # Converti l'immagine in una matrice numpy\n",
        "      segmentation_array = np.array(segmentation_true)\n",
        "\n",
        "      #----1)-----------DICHIARO LA MATRICE CHE CONTIENE LE CLASSI DELLA SEGMENTATION TRUTH----------#\n",
        "      # Mappa i valori dei pixel agli indici di classe (0-20)\n",
        "      class_matrix = segmentation_array.astype(int)\n",
        "\n",
        "      #controllo se nell'immagine di segmentazione truth è vuota per ADE20K\n",
        "      class_sem = np.unique(class_matrix)[1:-1]\n",
        "      exist_class_sem = 0\n",
        "      for a in class_sem:\n",
        "        exist_class_sem += class_ade20k_convertion[a - 1]\n",
        "      if exist_class_sem == 0:\n",
        "        continue \n",
        "      #----2)-----------ESTRAGGO LE IMMAGINI DA SEGMENTARE CON SAM------#\n",
        "      inizio = time.time()\n",
        "      image = cv2.imread(f\"{img_path}.jpg\")\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      masks = mask_generator.generate(image) # all model mask\n",
        "\n",
        "      plt.figure(figsize=(20, 20))\n",
        "      plt.imshow(image)\n",
        "      show_anns(masks)\n",
        "      plt.axis('off')\n",
        "\n",
        "      plt.savefig(f'{dir_output}/SAM.png')\n",
        "      fine = time.time()\n",
        "      tempo_di_esecuzione_sam = fine - inizio\n",
        "\n",
        "      #----3)----------CARICHIAMO LA MATRICE DELLA PREDIZIONE SEMANTICA---------#\n",
        "\n",
        "      img_seg = np.load(matrix_path)\n",
        "      img_seg_dpt = copy.copy(img_seg)\n",
        "\n",
        "      if os.path.isfile(f\"/content/drive/MyDrive/ProgettoSEAI/data/output_semseg/{img_name}.png\"):\n",
        "          # Sposta l'immagine nella cartella di destinazione\n",
        "          shutil.copy(f\"/content/drive/MyDrive/ProgettoSEAI/data/output_semseg/{img_name}.png\", f\"{dir_output}/semantic.png\")\n",
        "      else:\n",
        "         print(\"L'immagine di origine non esiste.\")\n",
        "\n",
        "      #----4)---------MERGIAMO SEMANTICA E SAM----------------#\n",
        "      inizio = time.time()\n",
        "\n",
        "      total_classes = np.unique(img_seg_dpt)\n",
        "      dict_class = dict.fromkeys(total_classes, 0)\n",
        "\n",
        "      # Popoliamo un dict_class per ogni maschera dell'immagine. vect_dict è un array di dict_class\n",
        "\n",
        "      vect_dict = create_vect_dict(masks,total_classes,img_seg)\n",
        "\n",
        "      max_classes = []  # la classe di ogni maschera\n",
        "      for dict_mask in vect_dict:\n",
        "          max_classes.append(max(dict_mask, key=dict_mask.get))\n",
        "\n",
        "      img_seg = merge(masks,max_classes,img_seg)\n",
        "\n",
        "      img = read_image(f\"{img_path}.jpg\")\n",
        "      write_segm_img(f'{dir_output}/sem_plus_sam', img, img_seg, alpha=0.5)\n",
        "      \n",
        "      fine = time.time()\n",
        "      tempo_di_esecuzione_sam_sem = fine - inizio\n",
        "      #ADE20K to PASCAL_VOC\n",
        "      matrix_sem_plus_sam= ade20k_to_pascalvoc(img_seg)\n",
        "\n",
        "      matrix_only_sem = ade20k_to_pascalvoc(img_seg_dpt)\n",
        "\n",
        "      \n",
        "      iou_sem_sam[\"iou_sem_sam\"] = iou(class_matrix, matrix_sem_plus_sam)\n",
        "      dice_sem_sam[\"dice_sem_sam\"] = dice_coefficient(class_matrix, matrix_sem_plus_sam)\n",
        "      iou_sem[\"iou_sem\"] = iou(class_matrix, matrix_only_sem)\n",
        "      dice_sem[\"dice_sem\"] = dice_coefficient(class_matrix, matrix_only_sem)\n",
        "      dict_metrics[img_name] = [iou_sem_sam,dice_sem_sam,iou_sem,dice_sem]\n",
        "      plt.close('all')    \n",
        "  \n",
        "  with open(f\"/content/drive/MyDrive/ProgettoSEAI/metriche/dict_metrics{part}.json\", \"w\") as file:\n",
        "    # Scrivi il dizionario nel file in formato JSON\n",
        "    json.dump(dict_metrics, file)\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "mm0kaylRB6SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10155857-33be-4441-af72-056ba50f84e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 91/91 [21:07<00:00, 13.93s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tempo_di_esecuzione_sam_sem)\n",
        "print(tempo_di_esecuzione_sam)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t53yDZfN2HjJ",
        "outputId": "e2997e8e-63bd-4f6f-e7a7-b9b8eff2e14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.920941591262817\n",
            "8.711585521697998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"DICE segmentazione finale: {dice_coefficient(class_matrix,img_seg)}\")\n",
        "print(f\"IOU segmentazione finale: {iou(class_matrix,img_seg)}\")\n",
        "print(f\"DICE segmentazione semantica: {dice_coefficient(class_matrix,img_seg_dpt)}\")\n",
        "print(f\"IOU segmentazione semantica: {iou(class_matrix,img_seg_dpt)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQs2BzhxYR-H",
        "outputId": "f715c6b2-ef98-49de-a016-bb027497595f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DICE segmentazione finale: 0.9780291518320012\n",
            "IOU segmentazione finale: 0.9570029845618706\n",
            "DICE segmentazione semantica: 0.976091943929132\n",
            "IOU segmentazione semantica: 0.9533003848751568\n"
          ]
        }
      ]
    }
  ]
}